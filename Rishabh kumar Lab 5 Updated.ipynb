{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b233a58d",
   "metadata": {
    "id": "b233a58d"
   },
   "source": [
    "# <font color=darkblue> Machine Learning model deployment with Flask framework</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4b2479",
   "metadata": {
    "id": "2c4b2479"
   },
   "source": [
    "## <font color=Blue>Used Cars Price Prediction Application</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7f286",
   "metadata": {
    "id": "bad7f286"
   },
   "source": [
    "### Objective:\n",
    "1. To build a Machine learning regression model to predict the selling price of the used cars based on the different input features like fuel_type, kms_driven, type of transmission etc.\n",
    "2. Deploy the machine learning model with the help of the flask framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c741642",
   "metadata": {
    "id": "3c741642"
   },
   "source": [
    "### Dataset Information:\n",
    "#### Dataset Source: https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho?select=CAR+DETAILS+FROM+CAR+DEKHO.csv\n",
    "This dataset contains information about used cars listed on www.cardekho.com\n",
    "- **Car_Name**: Name of the car\n",
    "- **Year**: Year of Purchase\n",
    "- **Selling Price (target)**: Selling price of the car in lakhs\n",
    "- **Present Price**: Present price of the car in lakhs\n",
    "- **Kms_Driven**: kilometers driven\n",
    "- **Fuel_Type**: Petrol/diesel/CNG\n",
    "- **Seller_Type**: Dealer or Indiviual\n",
    "- **Transmission**: Manual or Automatic\n",
    "- **Owner**: first, second or third owner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a340f92c",
   "metadata": {
    "id": "a340f92c"
   },
   "source": [
    "### 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "DekbG2Sm7L00",
   "metadata": {
    "id": "DekbG2Sm7L00"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a2da95",
   "metadata": {
    "id": "38a2da95"
   },
   "source": [
    "### 2. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "LS5P5wps7MOv",
   "metadata": {
    "id": "LS5P5wps7MOv"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = \"car+data.csv\"\n",
    "data = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ecd9c6",
   "metadata": {
    "id": "26ecd9c6"
   },
   "source": [
    "### 3. Check the shape and basic information of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wd8XSTpf7Mng",
   "metadata": {
    "id": "wd8XSTpf7Mng"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 301 entries, 0 to 300\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Car_Name       301 non-null    object \n",
      " 1   Year           301 non-null    int64  \n",
      " 2   Selling_Price  301 non-null    float64\n",
      " 3   Present_Price  301 non-null    float64\n",
      " 4   Kms_Driven     301 non-null    int64  \n",
      " 5   Fuel_Type      301 non-null    object \n",
      " 6   Seller_Type    301 non-null    object \n",
      " 7   Transmission   301 non-null    object \n",
      " 8   Owner          301 non-null    int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 21.3+ KB\n",
      "None\n",
      "  Car_Name  Year  Selling_Price  Present_Price  Kms_Driven Fuel_Type  \\\n",
      "0     ritz  2014           3.35           5.59       27000    Petrol   \n",
      "1      sx4  2013           4.75           9.54       43000    Diesel   \n",
      "2     ciaz  2017           7.25           9.85        6900    Petrol   \n",
      "3  wagon r  2011           2.85           4.15        5200    Petrol   \n",
      "4    swift  2014           4.60           6.87       42450    Diesel   \n",
      "\n",
      "  Seller_Type Transmission  Owner  \n",
      "0      Dealer       Manual      0  \n",
      "1      Dealer       Manual      0  \n",
      "2      Dealer       Manual      0  \n",
      "3      Dealer       Manual      0  \n",
      "4      Dealer       Manual      0  \n"
     ]
    }
   ],
   "source": [
    "# Check the shape\n",
    "print(data.shape)\n",
    "\n",
    "# Check the basic information\n",
    "print(data.info())\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06991b14",
   "metadata": {
    "id": "06991b14"
   },
   "source": [
    "### 4. Check for the presence of the duplicate records in the dataset? If present drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "-u5XA5d47Nbe",
   "metadata": {
    "id": "-u5XA5d47Nbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records: 2\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate records: {duplicates}\")\n",
    "\n",
    "# Drop duplicates if any\n",
    "if duplicates > 0:\n",
    "    data = data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367efc0b",
   "metadata": {
    "id": "367efc0b"
   },
   "source": [
    "### 5. Drop the columns which you think redundant for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gPMZesyr7OHb",
   "metadata": {
    "id": "gPMZesyr7OHb"
   },
   "outputs": [],
   "source": [
    "# Drop the 'Car_Name' column as it is redundant for the analysis\n",
    "data = data.drop(['Car_Name'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3674f",
   "metadata": {
    "id": "7fb3674f"
   },
   "source": [
    "### 6. Extract a new feature called 'age_of_the_car' from the feature 'year' and drop the feature year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "-E8ZwwvE7Oe_",
   "metadata": {
    "id": "-E8ZwwvE7Oe_"
   },
   "outputs": [],
   "source": [
    "# Extract 'age_of_the_car' from 'Year'\n",
    "data['age_of_the_car'] = 2024 - data['Year']  # Assuming the current year is 2024\n",
    "data = data.drop(['Year'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a144b",
   "metadata": {
    "id": "8f3a144b"
   },
   "source": [
    "### 7. Encode the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "EUwBNILZ7PT9",
   "metadata": {
    "id": "EUwBNILZ7PT9"
   },
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "data = pd.get_dummies(data, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe4984",
   "metadata": {
    "id": "8afe4984"
   },
   "source": [
    "### 8. Separate the target and independent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39E39X1y7Pvq",
   "metadata": {
    "id": "39E39X1y7Pvq"
   },
   "outputs": [],
   "source": [
    "# Separate the target and independent features\n",
    "X = data.drop(['Selling_Price'], axis=1)\n",
    "y = data['Selling_Price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c5ef9",
   "metadata": {
    "id": "e12c5ef9"
   },
   "source": [
    "### 9. Split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gvxCw7PF7Qon",
   "metadata": {
    "id": "gvxCw7PF7Qon"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86fbc33",
   "metadata": {
    "id": "e86fbc33"
   },
   "source": [
    "### 10. Build a Random forest Regressor model and check the r2-score for train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "IiEKH-kh7Rsw",
   "metadata": {
    "id": "IiEKH-kh7Rsw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score for Train Set: 0.9840594603786668\n",
      "R2 Score for Test Set: 0.547390441726516\n"
     ]
    }
   ],
   "source": [
    "# Build the Random Forest Regressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the train and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the r2-score for train and test sets\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"R2 Score for Train Set: {r2_train}\")\n",
    "print(f\"R2 Score for Test Set: {r2_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab525b11",
   "metadata": {
    "id": "ab525b11"
   },
   "source": [
    "### 11. Create a pickle file with an extension as .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "jLj3VeCH7Spb",
   "metadata": {
    "id": "jLj3VeCH7Spb"
   },
   "outputs": [],
   "source": [
    "# Save the model as a pickle file\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26246dc9",
   "metadata": {
    "id": "26246dc9"
   },
   "source": [
    "### 12. Create new folder/new project in visual studio/pycharm that should contain the \"model.pkl\" file *make sure you are using a virutal environment and install required packages.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2bd8b3",
   "metadata": {
    "id": "0f2bd8b3"
   },
   "source": [
    "### a) Create a basic HTML form for the frontend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3da56",
   "metadata": {
    "id": "d5a3da56"
   },
   "source": [
    "Create a file **index.html** in the templates folder and copy the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l6E1gBAZ7UD4",
   "metadata": {
    "id": "l6E1gBAZ7UD4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab774e57",
   "metadata": {
    "id": "ab774e57"
   },
   "source": [
    "### b) Create app.py file and write the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9r3rWra57UuQ",
   "metadata": {
    "id": "9r3rWra57UuQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "CBewpqT7MEbb",
   "metadata": {
    "id": "CBewpqT7MEbb"
   },
   "source": [
    "### 13. Run the app.py python file which will render to index html page then enter the input values and get the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8g7gvFyD7VHN",
   "metadata": {
    "id": "8g7gvFyD7VHN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e899b5a2",
   "metadata": {
    "id": "e899b5a2"
   },
   "source": [
    "### Happy Learning :)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
